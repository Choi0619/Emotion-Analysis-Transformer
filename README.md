# Emotion Analysis with Transformer

🚀 Implementation of a multi-head attention Transformer-based model for emotion analysis using the IMDb dataset.

## 📝 Description
This project demonstrates how to build a Transformer-based emotion analysis model. The implementation includes:
- Multi-head Attention (MHA) module
- Layer normalization, dropout, and residual connections
- A custom TextClassifier with positional encoding
- Training and evaluation on the IMDb dataset

## 📁 Project Structure
- **`Emotion_Analysis_with_Transformer.ipynb`**: Contains the full implementation, including data loading, model architecture, training, and evaluation.

## 🛠️ Requirements
To run this project, make sure to install the following dependencies:
- Python 3.7+
- PyTorch
- Transformers
- Datasets
- NumPy

Install the required libraries using pip:
```bash
pip install torch transformers datasets numpy
