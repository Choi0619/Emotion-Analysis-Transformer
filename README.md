# Emotion Analysis with Transformer

ğŸš€ Implementation of a multi-head attention Transformer-based model for emotion analysis using the IMDb dataset.

## ğŸ“ Description
This project demonstrates how to build a Transformer-based emotion analysis model. The implementation includes:
- Multi-head Attention (MHA) module
- Layer normalization, dropout, and residual connections
- A custom TextClassifier with positional encoding
- Training and evaluation on the IMDb dataset

## ğŸ“ Project Structure
- **`Emotion_Analysis_with_Transformer.ipynb`**: Contains the full implementation, including data loading, model architecture, training, and evaluation.

## ğŸ› ï¸ Requirements
To run this project, make sure to install the following dependencies:
- Python 3.7+
- PyTorch
- Transformers
- Datasets
- NumPy

Install the required libraries using pip:
```bash
pip install torch transformers datasets numpy
